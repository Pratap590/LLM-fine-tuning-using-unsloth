{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["# !pip install \"unsloth[colab] @ git+https://github.com/unslothai/unsloth.git\""],"metadata":{"id":"u2hBdZ4ybIDP","executionInfo":{"status":"ok","timestamp":1716406491494,"user_tz":-330,"elapsed":745,"user":{"displayName":"Rishi Raj","userId":"01044483557672676563"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["# !pip install \"git+https://github.com/huggingface/transformers.git\""],"metadata":{"id":"QP162FAacL-t","executionInfo":{"status":"ok","timestamp":1716406491495,"user_tz":-330,"elapsed":4,"user":{"displayName":"Rishi Raj","userId":"01044483557672676563"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# !pip install trl"],"metadata":{"id":"zZdLe2oXdFWA","executionInfo":{"status":"ok","timestamp":1716406491495,"user_tz":-330,"elapsed":4,"user":{"displayName":"Rishi Raj","userId":"01044483557672676563"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["from datasets import load_dataset\n","import pandas as pd"],"metadata":{"id":"ewwqNpvPdRgB","executionInfo":{"status":"error","timestamp":1716406492191,"user_tz":-330,"elapsed":11,"user":{"displayName":"Rishi Raj","userId":"01044483557672676563"}},"colab":{"base_uri":"https://localhost:8080/","height":331},"outputId":"88fdfb88-c9f4-45f8-9abd-e556318581e2"},"execution_count":4,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"No module named 'datasets'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-09f3f58319fb>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'datasets'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]},{"cell_type":"code","source":["# !pip install huggingface-cli"],"metadata":{"id":"H_3v68Zcg34f","executionInfo":{"status":"aborted","timestamp":1716406492191,"user_tz":-330,"elapsed":8,"user":{"displayName":"Rishi Raj","userId":"01044483557672676563"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!huggingface-cli login"],"metadata":{"id":"EUXMQcFFiJc7","executionInfo":{"status":"aborted","timestamp":1716406492192,"user_tz":-330,"elapsed":9,"user":{"displayName":"Rishi Raj","userId":"01044483557672676563"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","dataset = load_dataset(\"mememahal1/llama3-100-texts-sample\")"],"metadata":{"id":"t83uSHl3dZy9","executionInfo":{"status":"aborted","timestamp":1716406492192,"user_tz":-330,"elapsed":9,"user":{"displayName":"Rishi Raj","userId":"01044483557672676563"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset"],"metadata":{"id":"dvvptX3eddYD","executionInfo":{"status":"aborted","timestamp":1716406492192,"user_tz":-330,"elapsed":9,"user":{"displayName":"Rishi Raj","userId":"01044483557672676563"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from unsloth import FastLanguageModel\n","import torch\n","max_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\n","dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n","load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n","\n","# 4bit pre quantized models we support for 4x faster downloading + no OOMs.\n","fourbit_models = [\n","    # \"unsloth/mistral-7b-bnb-4bit\",\n","    # \"unsloth/mistral-7b-instruct-v0.2-bnb-4bit\",\n","    # \"unsloth/llama-2-7b-bnb-4bit\",\n","    # \"unsloth/gemma-7b-bnb-4bit\",\n","    # \"unsloth/gemma-7b-it-bnb-4bit\", # Instruct version of Gemma 7b\n","    # \"unsloth/gemma-2b-bnb-4bit\",\n","    # \"unsloth/gemma-2b-it-bnb-4bit\", # Instruct version of Gemma 2b\n","    \"unsloth/llama-3-8b-bnb-4bit\"] # [NEW] 15 Trillion token Llama-3"],"metadata":{"id":"KgwS8JUZdveF","executionInfo":{"status":"aborted","timestamp":1716406492193,"user_tz":-330,"elapsed":9,"user":{"displayName":"Rishi Raj","userId":"01044483557672676563"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model, tokenizer = FastLanguageModel.from_pretrained(\n","    model_name = \"unsloth/llama-3-8b-bnb-4bit\",\n","    max_seq_length = max_seq_length,\n","    dtype = dtype,\n","    load_in_4bit = load_in_4bit,\n","    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",")"],"metadata":{"id":"fdY1DYAbd1cw","executionInfo":{"status":"aborted","timestamp":1716406492193,"user_tz":-330,"elapsed":9,"user":{"displayName":"Rishi Raj","userId":"01044483557672676563"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = FastLanguageModel.get_peft_model(\n","    model,\n","    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n","    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n","                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n","    lora_alpha = 16,\n","    lora_dropout = 0, # Supports any, but = 0 is optimized\n","    bias = \"none\",    # Supports any, but = \"none\" is optimized\n","    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n","    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n","    random_state = 3407,\n","    use_rslora = False,  # We support rank stabilized LoRA\n","    loftq_config = None, # And LoftQ\n",")\n","EOS_TOKEN = tokenizer.eos_token # Must add EOS_TOKEN"],"metadata":{"id":"Ll0x9bBveAHV","executionInfo":{"status":"aborted","timestamp":1716406492194,"user_tz":-330,"elapsed":10,"user":{"displayName":"Rishi Raj","userId":"01044483557672676563"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["meme_prompt = \"\"\"Generate a one-liner caption (top text) for a meme image. The caption should directly answer the meme's context or question, adhering strictly to the format and tags provided. No additional commentary or text outside of the caption is required.\n","You must keep the following things in mind while creating top text:\n","1. Generate a funny top text in max 12-13 words without any emojis or anything extra. Keep it simple consisting only of words.\n","2. You have to make sure that the top text generated makes sense with the bottom text that is provided below.\n","3. Please don't give me any reasoning, explanation, arguments, or any explanation in brackets\n","4. Don't copy-paste words from the bottom text. Generate a top text such that when one reads the top text and then the bottom text one can make sense of the complete meme and also find it extremely funny\n","5. Try to use all the mandatory formats when we refresh the response\n","\n","\n","### Instruction:\n","{}\n","### Input:\n","{}\n","### Response:\n","{}\n","\"\"\"\n","def formatting_prompts_func(examples):\n","    instructions = examples[\"instruction\"]\n","    inputs       = examples[\"input\"]\n","    outputs      = examples[\"output\"]\n","    texts = []\n","    for instruction, input, output in zip(instructions, inputs, outputs):\n","        # Must add EOS_TOKEN, otherwise your generation will go on forever!\n","        text = meme_prompt.format(instruction, input, output) + EOS_TOKEN\n","        texts.append(text)\n","    return { \"text\" : texts, }\n","pass\n","\n","from datasets import load_dataset\n","dataset = load_dataset(\"vermaavesh/test_dataset\")\n","dataset = dataset.map(formatting_prompts_func, batched = True)"],"metadata":{"id":"wBmND3p0ebL7","executionInfo":{"status":"aborted","timestamp":1716406492194,"user_tz":-330,"elapsed":10,"user":{"displayName":"Rishi Raj","userId":"01044483557672676563"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset['train']"],"metadata":{"id":"JOvpL84_egMH","executionInfo":{"status":"aborted","timestamp":1716406492194,"user_tz":-330,"elapsed":10,"user":{"displayName":"Rishi Raj","userId":"01044483557672676563"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset1 = load_dataset(\"yahma/alpaca-cleaned\", split = \"train\")"],"metadata":{"id":"_XSKDlmIyZHg","executionInfo":{"status":"aborted","timestamp":1716406492194,"user_tz":-330,"elapsed":9,"user":{"displayName":"Rishi Raj","userId":"01044483557672676563"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from trl import SFTTrainer\n","from transformers import TrainingArguments\n","\n","trainer = SFTTrainer(\n","    model = model,\n","    tokenizer = tokenizer,\n","    train_dataset = dataset['train'],\n","    dataset_text_field = \"text\",\n","    max_seq_length = max_seq_length,\n","    dataset_num_proc = 2,\n","    packing = False, # Can make training 5x faster for short sequences.\n","    args = TrainingArguments(\n","        per_device_train_batch_size = 2,\n","        gradient_accumulation_steps = 4,\n","        warmup_steps = 5,\n","        max_steps = 60,\n","        learning_rate = 2e-4,\n","        fp16 = not torch.cuda.is_bf16_supported(),\n","        bf16 = torch.cuda.is_bf16_supported(),\n","        logging_steps = 1,\n","        optim = \"adamw_8bit\",\n","        weight_decay = 0.01,\n","        lr_scheduler_type = \"linear\",\n","        seed = 3407,\n","        output_dir = \"outputs\",\n","    ),\n",")"],"metadata":{"id":"8NwEpLI50TCJ","executionInfo":{"status":"aborted","timestamp":1716406492195,"user_tz":-330,"elapsed":10,"user":{"displayName":"Rishi Raj","userId":"01044483557672676563"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["gpu_stats = torch.cuda.get_device_properties(0)\n","start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n","max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n","print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n","print(f\"{start_gpu_memory} GB of memory reserved.\")"],"metadata":{"id":"96J_AjP11J6N","executionInfo":{"status":"aborted","timestamp":1716406492195,"user_tz":-330,"elapsed":10,"user":{"displayName":"Rishi Raj","userId":"01044483557672676563"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainer_stats = trainer.train()"],"metadata":{"id":"XgTZWNCw5NEu","executionInfo":{"status":"aborted","timestamp":1716406492195,"user_tz":-330,"elapsed":10,"user":{"displayName":"Rishi Raj","userId":"01044483557672676563"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n","used_memory_for_lora = round(used_memory - start_gpu_memory, 3)\n","used_percentage = round(used_memory         /max_memory*100, 3)\n","lora_percentage = round(used_memory_for_lora/max_memory*100, 3)\n","print(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\n","print(f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\")\n","print(f\"Peak reserved memory = {used_memory} GB.\")\n","print(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\n","print(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\n","print(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")"],"metadata":{"id":"Y2SlxQmj5SOG","executionInfo":{"status":"aborted","timestamp":1716406492196,"user_tz":-330,"elapsed":11,"user":{"displayName":"Rishi Raj","userId":"01044483557672676563"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# alpaca_prompt = Copied from above\n","def generate_meme(user_prompt, image_desc, template_text) -> str:\n","    FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n","    input_text = f\"Image Description: {image_desc}. Template Text: {template_text}\"\n","    inputs = tokenizer(\n","    [\n","        meme_prompt.format(\n","            user_prompt, # instruction\n","            input_text, # input\n","            \"\", # output - leave this blank for generation!\n","        )\n","    ], return_tensors = \"pt\").to(\"cuda\")\n","\n","    outputs = model.generate(**inputs, max_new_tokens = 64, use_cache = True)\n","    return tokenizer.batch_decode(outputs)[0].split(\"Response:\\n\")[-1].strip().rstrip(\":\")"],"metadata":{"id":"GfxZsoyY8KsK","executionInfo":{"status":"aborted","timestamp":1716406492196,"user_tz":-330,"elapsed":11,"user":{"displayName":"Rishi Raj","userId":"01044483557672676563"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["user_prompt = \"Humorous meme about the challenges of WFH (Work From Home) culture in India.\"\n","image_desc = \"In this image, an individual with a mustache is shown making a stern face, with his eyes wide open in a rather threatening manner. The text Amma Behen pe aa jaunga mai loosely translates to I will bring your mother and sister into this, suggesting a warning that things could escalate to involve family, which is often a serious turn in many cultures. The close-up and grainy quality of the image suggest it's a screen capture from a video, possibly adding to the dramatic effect.\"\n","template_text = \"Amma behen pe aa jaunga mai\"\n","\n","out = generate_meme(user_prompt, image_desc, template_text)\n","print(out)"],"metadata":{"id":"7rix8bOi8PNC","executionInfo":{"status":"aborted","timestamp":1716406492196,"user_tz":-330,"elapsed":11,"user":{"displayName":"Rishi Raj","userId":"01044483557672676563"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.save_pretrained(\"mememahal_unsloth-llama3-8b-bnb-4bit\") # Local saving\n","tokenizer.save_pretrained(\"mememahal_unsloth-llama3-8b-bnb-4bit\")"],"metadata":{"id":"L9CuMFGl8SZo","executionInfo":{"status":"aborted","timestamp":1716406492196,"user_tz":-330,"elapsed":11,"user":{"displayName":"Rishi Raj","userId":"01044483557672676563"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.push_to_hub(\"vermaavesh/mememahal_unsloth-llama3-8b-bnb-4bit\", token = \"...\") # Online saving\n","tokenizer.push_to_hub(\"vermaavesh/mememahal_unsloth-llama3-8b-bnb-4bit\", token = \"...\") # Online saving"],"metadata":{"id":"a0rznJlq8XmM","executionInfo":{"status":"aborted","timestamp":1716406492197,"user_tz":-330,"elapsed":12,"user":{"displayName":"Rishi Raj","userId":"01044483557672676563"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"W9ECrNLu8dDX","executionInfo":{"status":"aborted","timestamp":1716406492197,"user_tz":-330,"elapsed":11,"user":{"displayName":"Rishi Raj","userId":"01044483557672676563"}}},"execution_count":null,"outputs":[]}]}